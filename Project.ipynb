{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt # we only need pyplot\n",
    "sb.set() # set the default Seaborn style for graphics\n",
    "\n",
    "# Import Decision Tree Classifier model from Scikit-Learn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import json\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "animalData = pd.read_csv('train.csv')\n",
    "animalData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "petIDs = np.array(animalData[\"PetID\"])\n",
    "magnitude = []\n",
    "score = []\n",
    "\n",
    "# loop through IDs, do some math with the magnitudes and score and save that into a Numpy array, then add it to the animals Database\n",
    "for id in petIDs:\n",
    "  try: \n",
    "    with open(\"./train_sentiment/\" + id + '.json') as json_file:\n",
    "      itemData = json.load(json_file)\n",
    "      magnitude.append(itemData[\"documentSentiment\"][\"magnitude\"])\n",
    "      score.append(itemData[\"documentSentiment\"][\"score\"])\n",
    "  except:\n",
    "    magnitude.append(0.0)\n",
    "    score.append(0.0)\n",
    "    pass\n",
    "\n",
    "jsonData = {\"Magnitude\" : magnitude, \"Score\" : score}\n",
    "animalData = animalData.join(pd.DataFrame(data = jsonData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = animalData.drop([\"Name\", \"State\", \"RescuerID\", \"Description\", \"PetID\", \"AdoptionSpeed\", \"VideoAmt\", \"PhotoAmt\"], axis = 1)\n",
    "response = pd.DataFrame(animalData[\"AdoptionSpeed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(predictors, response, test_size = 0.25)\n",
    "\n",
    "svcModel = LinearSVC()\n",
    "\n",
    "svcModel.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = svcModel.predict(X_train)\n",
    "y_test_pred = svcModel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", svcModel.score(X_train, y_train))\n",
    "print()\n",
    "\n",
    "# Check the Goodness of Fit (on Test Data)\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", svcModel.score(X_test, y_test))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(y_train, y_train_pred)\n",
    "sb.heatmap(matrix, annot = True, fmt=\".0f\", annot_kws={\"size\": 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(y_test, y_test_pred)\n",
    "sb.heatmap(matrix, annot = True, fmt=\".0f\", annot_kws={\"size\": 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential models and functions from sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "y = response\n",
    "X = pd.DataFrame(predictors) \n",
    "\n",
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "# Random Forest using Train Data\n",
    "rforest = RandomForestClassifier(n_estimators = 100, max_depth = 15)  # create the object\n",
    "rforest.fit(X_train, y_train.values.ravel())                         # train the model\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_train_pred = rforest.predict(X_train)\n",
    "y_test_pred = rforest.predict(X_test)\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", rforest.score(X_train, y_train))\n",
    "print()\n",
    "\n",
    "# Check the Goodness of Fit (on Test Data)\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", rforest.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "# Plot the Confusion Matrix for Train and Test\n",
    "f, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "sb.heatmap(confusion_matrix(y_train, y_train_pred),\n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0])\n",
    "sb.heatmap(confusion_matrix(y_test, y_test_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animaldescription = pd.DataFrame(animalData[[\"Description\", \"AdoptionSpeed\"]])\n",
    "animaldescription.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for counting frequently occurence of spam and ham.\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#create empty list\n",
    "description1=[]\n",
    "alist = [\"good\",\"play\",\"love\",\"care\",\"vaccin\",'friendli',\"healthi\",\"activ\",\"cute\",\"rescu\"]\n",
    "blist =[]\n",
    "\n",
    "\n",
    "# Combines words with similar meaning together\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Removes words like \"it\", \"the\", etc.\n",
    "sw = stopwords.words(\"english\")\n",
    "\n",
    "for i in animaldescription['Description']:\n",
    "    i = str(i)\n",
    "    if i == 'nan':\n",
    "        i = 'blank'\n",
    "    text = i.lower()\n",
    "    words = word_tokenize(i)\n",
    "    words = [word for word in words if word not in sw]\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    words = [w for w in words if len(w) > 3]\n",
    "    blist.append(len([word for word in words if word in alist]))\n",
    "    words = ' '.join(str(e) for e in words)\n",
    "    description1.append(words)\n",
    "    \n",
    "    \n",
    "animaldescription['description1']=description1\n",
    "\n",
    "animaldescription= animaldescription.join(pd.DataFrame(data = {\"goodwords\" : np.array(blist)}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count1 = Counter(\" \".join(animaldescription[\"description1\"]).split()).most_common(30)\n",
    "data1 = pd.DataFrame.from_dict(count1)\n",
    "data1 = data1.rename(columns={0: \"words of description\", 1 : \"count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.plot.bar(legend = False, color = 'purple',figsize = (20,15))\n",
    "y_pos = np.arange(len(data1[\"words of description\"]))\n",
    "plt.xticks(y_pos, data1[\"words of description\"])\n",
    "plt.title('Top 30 words of description')\n",
    "plt.xlabel('words')\n",
    "plt.ylabel('number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = response\n",
    "X = predictors.join(pd.DataFrame(animaldescription[\"goodwords\"]))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "\n",
    "# Decision Tree using Train Data\n",
    "dectree = DecisionTreeClassifier(max_depth = 8)  # create the decision tree object\n",
    "dectree.fit(X_train, y_train)                    # train the decision tree model\n",
    "\n",
    "# Plot the Decision Tree\n",
    "treedot = export_graphviz(dectree,                                      # the model\n",
    "                          feature_names = X_train.columns,              # the features \n",
    "                          out_file = None,                              # output file\n",
    "                          filled = True,                                # node colors\n",
    "                          rounded = True,                               # make pretty\n",
    "                          special_characters = True)                    # postscript\n",
    "\n",
    "\n",
    "graphviz.Source(treedot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Legendary values corresponding to Total\n",
    "y_train_pred = dectree.predict(X_train)\n",
    "y_test_pred = dectree.predict(X_test)\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_train, y_train))\n",
    "print()\n",
    "\n",
    "# Check the Goodness of Fit (on Test Data)\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "# Plot the Confusion Matrix for Train and Test\n",
    "f, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "sb.heatmap(confusion_matrix(y_train, y_train_pred),\n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0])\n",
    "sb.heatmap(confusion_matrix(y_test, y_test_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
